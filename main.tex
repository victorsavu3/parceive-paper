\documentclass[conference]{IEEEtran}

\ifCLASSOPTIONcompsoc
  \usepackage[nocompress]{cite}
\else
  \usepackage{cite}
\fi

\usepackage[pdftex]{graphicx}
\graphicspath{{../img/}}

\begin{document}

\title{Parceive\\The Paper}

\author{A. Wilhelm,
		V. Savu
        and~E. Amadasun}% <-this % stops a space

\IEEEtitleabstractindextext{%
\begin{abstract}
The abstract goes here.
\end{abstract}

\begin{IEEEkeywords}
Computer Society, IEEE, IEEEtran, journal, \LaTeX, paper, template.
\end{IEEEkeywords}}

\maketitle


\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle

\section{Introduction}
\label{sec:introduction}

\section{Parallelization}
\label{sec:parallelization}

\section{Parceive}
\label{sec:parceive}

\subsection{System Architecture}
\label{sec:system_architecture}

\subsection{Data Model}
\label{sec:data_model}

\subsection{Data Extraction}
\label{sec:data_extraction}

\section{Views}
\label{sec:views}

\subsection{Performance View}
\label{sec:performance_view}

The performance view provides an interactive visualization of a program's profiling and event trace data. Its primary purpose is to assist users in identifying scenarios that could potentially improve performance, by employing parallel programming as an optimization solution. Tracing and profiling data provide valuable material for detailed analysis on how a program behaves at runtime, and presenting a wholistic view of this data in an easy to digest visualization, can help users quickly comprehend the program, spot potential performance bottlenecks, and help guide optimization efforts.

Two visualization modes are provided in the performance view: Tracing, and profiling. The tracing mode presents a hierarchical view of calls made during the execution of a program. The calls are arranged from left to right chronologically, and the visibility of the loop information for each call with a loop execution can be toggled on/off. The trace visualization is useful for detailed examination of a program, especially where the sequence in which calls were made is important. The profiling mode presents the user with a hierarchical view of the functions called during a program's execution. The length of each function in the view is dictated by the sum of the duration of calls made to it. The profiling visualization is often sufficient to pinpoint load imbalance due to problem decomposition and/or identify the origin of excessive communication time.

As a program grows in size and complexity, the performance data also grows, and becomes harder to digest all at once. Which is why the performance view provides call zooming and runtime duration filtering features, to help the user adjust the view to different data granularity levels. Runtime duration filtering is a feature that sets the minimum runtime duration required for a call to be loaded unto the view. The minimum runtime duration value is gotten by calculating a specified percentage of the runtime duration of the current top-level call in the view. This feature allows the view render only calls large enough to be easily visible. With the call zooming feature, a user can focus the view on a specific call, which then makes it the top-level call, re-computes a new minimum runtime duration, and loads any child calls of the focused call that wasn't visible due to the previous runtime duration constraint.

The view is built and deployed on the visualization framework that is part of the Parcieve UI. The visualization framework provides a platform for the view to be delivered to the web, and it also provides an API through which performance data for a program can be accessed. The performance view is able to interact with other views on Parceive, by leveraging the event API provided by the visualization framework. Through the event API, the performance view is able to broadcast relevant data to other views when calls and loops are hovered over with the mouse pointer, selected, or zoomed into.

\subsection{CCT View}
\label{cct_view}

\section{Case Studies}
\label{sec:case_studies}

\subsection{CppCheck}
\label{sec:cppcheck}

\subsection{TensorFlow}
\label{sec:tensorflow}

\section{Discussion}
\label{sec:discussion}

\section{Related Work}
\label{sec:related_work}

\subsection{Software Comprehension}
\label{sec:software_comprehension}

\subsection{Parallelization}
\label{sec:related_work_parallelization}

\section{Conclusion}
\label{sec:conclusion}

\section{Framework}

\subsection{Database processing}
\label{dataprocessing}

The database layout and settings used by Parceive are highly optimized for fast writing. All the information required by the visualization can be obtained by using queries, but most of the operations will take a disproportionate amount of time to complete.

The first problem with the database is that Parceive avoids the creation of indexes to improve write performance. Thus, the most important step of the database processing is the creation of multiple indexes to improve record lookup. All primary and foreign keys are indexed and some composite indexes are created to speed up specific queries.

Since no additional data will be added to the database, creating redundancy generates no overhead and does not increase the complexity. By adding additional fields and creating intermediary tables, it is possible to avoid joins for most queries executed by the visualizations. 

Executing \texttt{VACUUM} after all processing is done also improves performance by reducing the fragmentation of data stored inside tables. The increased locality of data reduces the execution time of most queries and has a considerable effect on ones that require a full table scan. \texttt{VACUUM} is also able to reduce the size of the processed database.

\subsubsection*{Performance}

Figure \ref{parceive:procperformance} shows the time and size overhead of processing databases generated by Parceive. The time required by this operation is negligible because loading most visualizations without the optimizations would waste more than the processing itself. The executed queries are also heavily optimized making \texttt{VACUUM} and the creation of indexes the most time consuming operations. The size increase is unfortunately unavoidable.

\begin{figure}
	\centering
	\begin{tabular}{l l l l}
		Database & Size & Processed Size & Time taken \\
		emsim\_par & 3905536 & 14560256 & 8.77 s
	\end{tabular}
	\caption{Database processing performance}
	\label{parceive:procperformance}
\end{figure}

\subsection{NodeJS Server}

Loading the entire database into the browser is not possible when the trace is too large. To solve this problem a simple NodeJS Server was developed to read data from a processed database on demand.

The server exposes a very simple REST \cite{rest} API that only allows the retrieval of data. For security reasons all SQL queries are contained in this server and  arbitrary queries are not supported. The implementation makes use of multiple parallel reads to the same database to reduce the latency and throughput when large amounts of data is requested by the visualizations.

\subsection{ORM}

Visualizations developed within the Parceive architecture can employ a Object Relational Mapper to simplify development and improve performance. The ORM makes it possible to access entities and to easily navigate the relationships between them. The API is implemented using promises \cite{promises} simplifying the asynchronous and parallel behavior.

The greatest benefit to using this ORM in visualizations is the possibility of applying optimizations to the data loading. The most important ones are caching and pipelining.

Caching allows the ORM to avoid loading data that has been accessed before. Each time an entity is retrieved from the server it is saved and reused for subsequent requests. This optimization allows visualizations to focus more on data presentation instead of efficient data retrieval.

Pipelining combines multiple queries to the same endpoint into a single one. When requesting a large number of entities it can improve performance despite the limit on the number of parallel requests in browsers. This optimization is designed to greatly increase throughput at the cost of a response time increased by 10 milliseconds.

\subsection{Visualization Framework}

As part of the Parceive UI a visualization framework has been developed to handle the layout and communication of multiple visualizations. The implementation is based on AngularJS and it completely separates visualizations into separate applications.

\subsubsection{State management}

The visualization framework implements a centralized and persistent state storage for visualizations. With the use of this feature it is possible to retain the state of views across page loads.

Currently the view layout and the marked nodes are stored as part of the state automatically. In addition to this each visualization can save tailored information at any time and retrieve it when rendering. Local storage is used to house all the state information making it persistent.

\subsubsection{Communication}

Visualizations perform different tasks and allow the user to navigate the callgraph in different ways. Communication makes it possible to follow a chain of investigation along multiple visualizations. Currently there are three ways to communicate intent:

\begin{itemize}
	\item[Focus] brings entities to the attention of the user
	\item[Mark] allows the creation of selections that are visible between visualizations
	\item[Spot] replaces all the entities in a visualization with a new set
	\item[Hover] brings entities to the attention of the user using opacity
\end{itemize}


\section{Visualizations}

\subsection{Source View}

The source view is the simplest visualization developed for Parceive. It shows the highlighted source code in a file that was used to build the instrumented application.

The usefulness of this view only becomes apparent when it is communicating with the others presented in this paper. The simplest interaction is focusing and it allows the source view to pinpoint the definition of functions an loops making it easy to follow the execution of a program trough the source code.

Hovering is able to provide additional information about entities. For calls it can indicate where the call originated and for memory references where they were allocated and referenced.

\subsection{Calling context tree View}

The CCT View is a visualization that allows an user to easily comprehend the dynamic behavior of an application. It can display and easily navigate Calls, Loops and References.

The first node present when the view is created is the call to \texttt{main}. The user can then expand it like any other call by clicking or using the context menu. When a function is called multiple times the calls are grouped into a CallGroup to reduce the number of nodes displayed. CallGroups can be easily decomposed into their Calls by using the context menu.

Loops can be visually identified by icons on nodes. When a loop icon is present on the right side of a node then that node contains one or more loops. These loops can be added to the visualization by using the context menu. A icon on the left side indicates that the call has been made from inside a loop. Navigating loop executions and loop iterations is similar to calls and allows the user to see information at any granularity he desires.

CallGroups, Calls, LoopExecutions and LoopIterations are positioned using the D3 tree layout. Children of a node are always sorted by their start time. This positioning of nodes creates a clear indicator of the relationship between them.

References accessed by parts of the application can be displayed by using the context menu. These nodes are difficult to integrate as part of a graph layout and are positioned using a force simulation around the rest of the tree.

This view has some additional features that aim to help a developer parallelize code:

\begin{itemize}
	\item Profiling information is present as the node color
	\item References shared between nodes can be easily identified
	\item It is easy to expand the references accessed during the inclusive execution of a call or callgroup
	\item A specialized query that only display the shared references between nodes
\end{itemize}

\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{}
Appendix two text goes here.

% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\end{document}



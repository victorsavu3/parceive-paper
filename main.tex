\documentclass[conference]{IEEEtran}

\ifCLASSOPTIONcompsoc
  \usepackage[nocompress]{cite}
\else
  \usepackage{cite}
\fi

\usepackage[pdftex]{graphicx}
\graphicspath{{../img/}}

\begin{document}

\title{Parceive\\The Paper}

\author{A. Wilhelm,
		V. Savu
        and~E. Amadasun}% <-this % stops a space

\IEEEtitleabstractindextext{%
\begin{abstract}
The abstract goes here.
\end{abstract}

\begin{IEEEkeywords}
Computer Society, IEEE, IEEEtran, journal, \LaTeX, paper, template.
\end{IEEEkeywords}}

\maketitle


\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle

\section{Introduction}
\label{sec:introduction}

\section{Parallelization}
\label{sec:parallelization}

\section{Parceive}
\label{sec:parceive}

\subsection{System Architecture}
\label{sec:system_architecture}

\subsection{Data Model}
\label{sec:data_model}

\subsection{Data Extraction}
\label{sec:data_extraction}

\section{Views}
\label{sec:views}

\subsection{Profiling View}
\label{sec:profiling_view}

\subsection{CCT View}
\label{cct_view}

\section{Case Studies}
\label{sec:case_studies}

\subsection{CppCheck}
\label{sec:cppcheck}

\subsection{TensorFlow}
\label{sec:tensorflow}

\section{Discussion}
\label{sec:discussion}

\section{Related Work}
\label{sec:related_work}

\subsection{Software Comprehension}
\label{sec:software_comprehension}

\subsection{Parallelization}
\label{sec:related_work_parallelization}

\section{Conclusion}
\label{sec:conclusion}

\section{Framework}

\subsection{Database processing}
\label{dataprocessing}

The database layout and settings used by Parceive are highly optimized for fast writing. All the information required by the visualization can be obtained by using queries, but most of the operations will take a considerable amount of time to complete.

The first problem with the database is that Parceive avoids the creation of indexes to improve write performance. Thus, the most important step of the database processing is the creation of multiple indexes to improve record lookup. All primary and foreign keys are indexed and some composite indexes are created to speed up specific queries.

Since no additional data will be added to the database, inserting redundant data creates no overhead and does not increase the complexity. By adding additional fields and creating intermediary tables it is possible to avoid joins for most queries executed by the visualizations. 

Executing \texttt{VACUUM} after all processing is done also improves performance by reducing the fragmentation of data stored inside tables. The increased locality of data reduces the execution time of most queries and has a considerable effect on ones that require a full table scan. \texttt{VACUUM} is also able to reduce the size of the processed database.

\subsubsection{Optimization examples}

1. One of the most intuitive and beneficial information added to the database is the \texttt{Caller} field in the \texttt{Call} table. Obtaining the calls performed by one specific call normally requires a join on three tables \texttt{Call}, \texttt{Instruction} and \texttt{Segment} and can be completely avoided by this shortcut.

2. Showing profiling information of a call would require querying all calls made. If loops are present most of the calls would be made to the same function. The creation of the \texttt{CallGroup} table reduces the number of entities returned considerably by grouping together all calls to the same function. A profiler can avoid the \texttt{Call} table completely by using \texttt{CallGroup}.

3. SQL is not designed to handle tree structures such as the call graph present in an application. The \texttt{CallTree} and \texttt{CallGroupTree} tables contain a flattened representation of the graph that can be queried in a simple and readable manner. Complex queries only become possible by using of these intermediary tables. The following queries would require hours of processing time if not optimized:

\begin{itemize}
	\item The references accessed during the execution of a call
	\item Loading an entire call graph at once
\end{itemize}

\subsubsection{Performance}

Figure \ref{parceive:procperformance} shows the time and size overhead of processing databases generated by Parceive. The time required by this operation is negligible because loading most visualizations without the optimizations would waste more than the processing itself. The executed queries are also heavily optimized making \texttt{VACUUM} and the creation of indexes the most time consuming operations. The size increase is unfortunately unavoidable.

\begin{figure}
	\centering
	\begin{tabular}{l l l l}
		Database & Size & Processed Size & Time taken \\
		emsim\_par & 3905536 & 14560256 & 8.77 s
	\end{tabular}
	\caption{Database processing performance}
	\label{parceive:procperformance}
\end{figure}

\subsection{NodeJS Server}

Loading the entire database into the browser is not possible when the trace is too large. To solve this problem a simple NodeJS Server was developed to read data from a processed database on demand.

The server exposes a very simple REST \cite{rest} API that only allows the retrieval of data. For security reasons all SQL queries are contained in this server and  arbitrary queries are not supported. The server makes use of multiple parallel reads to the same database to reduce the latency and throughput when large amounts of data is requested by the visualizations.

\subsection{ORM}

Visualizations developed within the Parceive architecture can employ a Object Relational Mapper to simplify development and improve performance. The ORM makes it possible to access entities and to easily navigate the relationships between them. The API is implemented using promises \cite{promises} simplifying the asynchronous and parallel behavior.

The greatest benefit to using this ORM in visualizations is the possibility of applying optimizations to the data loading. The most important ones are caching and pipelining.

Caching allows the ORM to avoid loading data that has been accessed before. Each time an entity is retrieved from the server it is saved and reused for subsequent requests. This optimization allows visualizations to focus more on data presentation instead of data retrieval.

Pipelining combines multiple queries to the same endpoint into a single one. When requesting a large number of entities it can improve performance despite the limit on the number of parallel requests in browsers. This optimization is designed to greatly increase throughput at the cost of a response time increased by 10 milliseconds.

\subsection{Visualization Framework}

As part of the Parceive UI a visualization framework has been developed to handle the layout and communication of multiple visualizations. The implementation is based on AngularJS and it completely separates visualizations into separate applications.

\subsubsection{State management}

The visualization framework also implements a centralized and persistent state management for visualizations. With the use of this feature it is possible to retain the state of views across page views.

Currently the view layout and the marked nodes are stored as part of the state automatically. In addition to this each visualization can save tailored information at any time and retrieve it when rendering. Local storage is used to house all the state information making it persistent.

\subsubsection{Communication}

Visualizations perform different tasks and allow the user to navigate the callgraph in different ways. Communication makes it possible to follow a chain of investigation along multiple visualizations. Currently there are three ways to communicate intent:

\begin{itemize}
	\item[Focus] brings entities to the attention of the user
	\item[Mark] allows the creation of selections that are visible between visualizations
	\item[Spot] replaces all the entities in a visualization with a new set
	\item[Hover] brings entities to the attention of the user using opacity
\end{itemize}


\section{Visualizations}

\subsection{Source View}

The source view is the simplest visualization developed for Parceive. It shows the highlighted source code for a file that was used to build the instrumented application.

The usefulness of this view only becomes apparent when it is communicating with the others presented in this paper. Te simplest interaction is focusing and it allows the source view to pinpoint the definition of functions an loops making it easy to follow the execution of a program trough the source code.

Hovering is able to provide additional information about entities. For calls it can indicate where the call originated and for memory references where they were allocated and referenced.

\subsection{Calling context tree View}

The CCT View is a visualization that allows an user to easily comprehend the dynamic behavior of an application. It is able to display and easily navigate Calls, Loops and References.

The first node present when the view is created is the call to \texttt{main}. The user can then expand it like any other call by clicking or using the context menu. When a function is called multiple times the calls are grouped into a CallGroup to reduce the number of nodes displayed. CallGroups can be easily decomposed into their Calls by using the context menu.

Loops can be visually identified by icons on nodes. When a loop icon is present on the right side of a node then that node contains one or more loops. These loops can be displayed by using the context menu. A icon on the left side indicates that the call has been made from inside a loop. Navigating loop executions and loop iterations is similar to calls and can be easily performed.

CallGroups, Calls, LoopExecutions and LoopIterations are positioned using the D3 tree layout. Children of a node are always sorted by their start time. This positioning of nodes is a clear indication for the relationship between them.

References accessed by parts of the application can be shown by using the context menu. These nodes are difficult to integrate as part of a graph layout and are positioned using a force simulation around the rest of the tree.

This view has some features that aim to help a developer parallelize code:

\begin{itemize}
	\item Profiling information is present as the node color
	\item References shared between nodes can be easily identified
	\item It is easy to expand the references accessed during the inclusive execution of a call or callgroup
	\item A specialized query to only display the shared references between nodes
\end{itemize}

\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{}
Appendix two text goes here.

% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\end{document}


